library(plyr)
library(dplyr)
library(tm)
library(stringr)
library(tidytext)
library(ggplot2)
# load the input data, add a "category" column and bind them all into one
path = "./Dataset/"
dir = DirSource(paste(path,sep=""), encoding = "UTF-8")
corpus = Corpus(dir)
length(corpus)
#corpus <- tolower(corpus)
tdm = TermDocumentMatrix(corpus,control = list(removePunctuation = T,
removeNumbers = T,
stemming = T))
( tf <- as.matrix(tdm) ) #frequency of each term in entire corpus
idf <- tf
library(plyr)
library(dplyr)
library(tm)
library(stringr)
library(tidytext)
library(ggplot2)
# load the input data, add a "category" column and bind them all into one
path = "./Dataset/"
dir = DirSource(paste(path,sep=""), encoding = "UTF-8")
corpus = Corpus(dir)
length(corpus)
#corpus <- tolower(corpus)
View(corpus)
myStopwords = c(stopwords(),"crime","crimes","security","securities","i.e.", "would", "get", "like", "using", "know", "question", "use",
"get", "possible" , "aah",
"much", "find", "anyone",'able', 'according', 'accordingly', 'across',
'actually', 'afterwards', "ain't", 'allow', 'allows', 'almost',
"tell", "know", "another", "various", "also", "etc", "around", "vs",
"used", "could", "without", "way", "new",
'alone', 'along', 'already', 'although', 'always', 'among',
'amongst', 'anybody', 'anyhow', 'anything',
'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate',
'appropriate', 'aside', 'ask', 'asking',
'associated', 'available', 'away', 'awfully',
'b', 'be', 'became', 'become', 'becomes',
'becoming', 'been', 'before', 'beforehand', 'behind', 'being',
'believe', 'below', 'beside', 'besides', 'best', 'better',
'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', "c'mon",
"c's", 'came', 'can', "can't", 'cannot', 'cant', 'cause',
'causes', 'certain', 'certainly', 'changes', 'clearly', 'co',
'com', 'come', 'comes', 'concerning', 'consequently', 'consider',
'considering', 'contain', 'containing', 'contains',
'corresponding', 'could', "couldn't", 'course', 'currently', 'd',
'definitely', 'described', 'despite', 'did', "didn't", 'didnt',
'different', 'do', 'does', "doesn't", 'doesnt','doing', "don't",
'dont', 'done',
'down', 'downwards', 'during', 'e', 'each', 'edu', 'eg', 'eight',
'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially',
'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone',
'everything', 'everywhere', 'ex', 'exactly', 'example', 'except',
'f', 'far', 'few', 'fifth', 'first', 'five', 'followed',
'following', 'follows', 'for', 'former', 'formerly', 'forth',
'four', 'from', 'further', 'furthermore', 'g', 'get', 'gets',
'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got',
'gotten', 'greetings', 'h', 'had', "hadn't",'hadnt', 'happens', 'hardly',
'has', "hasn't", 'hasnt','have', "haven't",'havent', 'having',
'he', "he's",'hes', 'hello', 'help', 'hence', 'her', 'here',
"here's",'heres', 'hereafter',
'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him',
'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit',
'however', 'i', "i'd", 'id','ill',"i'll", "i'm", 'im', "i've",
'ive','isnt', "isn't", 'ie', 'if',
'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed',
'indicate', 'indicated', 'indicates', 'inner', 'insofar',
'instead', 'into', 'inward', 'is', "isn't",'isnt', 'it', "it'd",
'itd','itll', "it'll",
"it's", 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps',
'kept', 'know', 'knows', 'known', 'l', 'last', 'lately', 'later',
'latter', 'latterly', 'least', 'less', 'lest', 'let', "let's",
'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks',
'ltd', 'm', 'mainly', 'many', 'may', 'maybe', 'me', 'mean',
'meanwhile', 'merely', 'might', 'more', 'moreover', 'most',
'mostly', 'much', 'must', 'my', 'myself', 'n', 'name', 'namely',
'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither',
'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody',
'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing',
'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often',
'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only',
'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our',
'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own',
'p', 'particular', 'particularly', 'per', 'perhaps', 'placed',
'please', 'plus', 'possible', 'presumably', 'probably', 'put',
'provides', 'q', 'que', 'quite', 'qv', 'r', 'rather', 'rd', 're',
'really', 'reasonably', 'regarding', 'regardless', 'regards',
'relatively', 'respectively', 'right', 's', 'said', 'same', 'saw',
'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing',
'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves',
'sensible', 'sent', 'serious', 'seriously', 'seven', 'several',
'shall', 'she', 'should', "shouldn't", 'since', 'six', 'so',
'some', 'somebody', 'somehow', 'someone', 'something', 'sometime',
'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry',
'specified', 'specify', 'specifying', 'still', 'sub', 'such',
'sup', 'sure', 't', "t's", 'take', 'taken', 'tell', 'tends', 'th',
'than', 'thank', 'thanks', 'thanx', 'that', "that's", 'thats',
'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence',
'there', "there's", 'theres', 'thereafter', 'thereby', 'therefore',
'therein', 'theres', 'thereupon', 'these', 'they', "they'd", 'theyd',
'theyll', 'theyre',
"they'll", "they're", "they've", 'think', 'third', 'this', 'theyve',
'thorough', 'thoroughly', 'those', 'though', 'three', 'through',
'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took',
'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying',
'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless',
'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used',
'useful', 'uses', 'using', 'usually', 'uucp', 'v', 'value',
'various', 'very', 'via', 'viz', 'vs', 'w', 'want', 'wants',
'was', "wasn't", 'wasnt', 'way', 'we', "we'd", "we'll", "we're", "we've",
'wed', 'well', 'were', 'weve', 'werent', 'whats', 'wheres',
'whos','wont','wouldnt',
'welcome', 'well', 'went', 'were', "weren't", 'what', "what's",
'whatever', 'when', 'whence', 'whenever', 'where', "where's",
'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon',
'wherever', 'whether', 'which', 'while', 'whither', 'who',
"who's", 'whoever', 'whole', 'whom', 'whose', 'why', 'will',
'willing', 'wish', 'with', 'within', 'without', "won't", 'wonder',
'would', 'would', "wouldn't", 'x', 'y', 'yes', 'yet', 'you',
'youd', 'youll', 'youre', 'youve',
"you'd", "you'll", "you're", "you've", 'your', 'yours',
'yourself', 'yourselves', 'z', 'zero')
tdm = TermDocumentMatrix(corpus,control = list(removePunctuation = T,
removeNumbers = T,
stemming = T))
#q3
( tf <- as.matrix(tdm) ) #frequency of each term in entire corpus
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
idf
setwd("~/Desktop/IR/Dataset")
filenames <- list.files(pattern="*.txt")
text.tagged <- lapply(filenames, function(x) treetag(x, treetagger="manual", lang="en",
TT.options=list(path=filepath, preset="en")))
library(lapply)
( tf <- as.matrix(tdm) )
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
( tf <- as.matrix(tdm) )
tfLog  <- ifelse(tf>0,1+log10(tf),0)
tfLog
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
( tf <- as.matrix(tdm) )
tfLog  <- ifelse(tf>0,1+log10(tf),0)
tfLog
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
idf
tf.idf <- tfLog*idf
tf.idf
freq=rowSums(as.matrix(tf.idf))
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
( tf <- as.matrix(tdm) )
View(tdm)
View(tf)
tf.idf <- tfLog*idf
tf.idf
View(tf.idf)
barplot(sort(decreasing = T, freq),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
tail(sort(freq),n=11)
plot(sort(decreasing = T, freq),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
tail(sort(freq),n=11)
freq=rowSums(as.matrix(tf.idf))
high.freq=tail(sort(freq),n=11)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df)
ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Query Terms") + ylab("FIDF") +
ggtitle("IDF Bar Chart")
freq=rowSums(as.matrix(idf))
high.freq=tail(sort(freq),n=11)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df)
ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Query Terms") + ylab("IDF") +
ggtitle("IDF Bar Chart")
# Simple Pie Chart
x=freq
pie(x, labels = names(x), edges = 200, radius = 0.8,
)
freq=rowSums(as.matrix(idf))
high.freq=tail(sort(freq),n=11)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df)
ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Query Terms") + ylab("IDF") +
ggtitle("IDF Bar Chart")
data <- as.matrix(tf.idf)
library(RColorBrewer)
my_group <- as.numeric(as.factor(substr(rownames(data), 1 , 1)))
colSide <- brewer.pal(9, "Set1")[my_group]
colMain <- colorRampPalette(brewer.pal(8, "Blues"))(25)
heatmap(data, Colv = NA, Rowv = NA, scale="column" , RowSideColors=colSide, col=colMain )
#wordcloud
library(wordcloud)
inspect(corpus)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
corpus <- tm_map(corpus, toSpace, "/")
corpus <- tm_map(corpus, toSpace, "@")
corpus <- tm_map(corpus, toSpace, "\\|")
# Convert the text to lower case
corpus <- tm_map(corpus, content_transformer(tolower))
# Remove numbers
corpus <- tm_map(corpus, removeNumbers)
# Remove english common stopwords
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
corpus <- tm_map(corpus, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
corpus <- tm_map(corpus, removePunctuation)
# Eliminate extra white spaces
corpus <- tm_map(corpus, stripWhitespace)
# Text stemming
# corpus <- tm_map(corpus, stemDocument)
dtm <- TermDocumentMatrix(corpus)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=1000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
qtf.idf <- cbind(tdm,query)
qtf.idf
pr_DB$set_entry(FUN = cosd, names = c("cosd"))
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
d1
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
View(d1)
View(hfp.df)
View(d1)
pr_DB$set_entry(FUN = cosd, names = c("cosd"))
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
View(d1)
idf <- log10(ncol(tf)/rowSums(idf))
idf
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
idf
idf <- tf
library(tm)
library(ggplot2)
#q1#
path = "./Dataset/"
dir = DirSource(paste(path,sep=""), encoding = "UTF-8")
corpus = Corpus(dir)
length(corpus)
#corpus[[1]]$content
#strwrap(corpus)
myStopwords = c(stopwords(),"crime","crimes","security","securities")
tdm = TermDocumentMatrix(corpus,
control = list(weighting = weightTfIdf,
stopwords = myStopwords,
removePunctuation = T,
removeNumbers = T,
stemming = T))
( tf <- as.matrix(tdm) ) #frequency of each term in entire corpus
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
idf
library(SnowballC)
#inspect(tdm[2005:2015,100:103])
freq=rowSums(as.matrix(tf))
View(freq)
head(freq,10)
tail(freq,10)
barplot(sort(freq, decreasing = T),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
tail(sort(freq),n=10)
high.freq=tail(sort(freq),n=10)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df)
ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Terms") + ylab("Frequency") +
ggtitle("Term frequencies")
# q2
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
#( tf <- as.matrix(tdm) )
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
( tf <- as.matrix(tdm) )
tfLog  <- ifelse(tf>0,1+log10(tf),0)
tfLog
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
idf
View(idf)
View(tfLog)
View(tf.idf)
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
View(d1)
load("/Users/ciel/Downloads/rf.cv.1.RData")
load("/Users/ciel/Downloads/rf.cv.1.RData")
library(proxy)
cosd<- function(x, y) {
similarity <- sum(x * y) / ( sqrt( sum(y ^ 2) ) * sqrt( sum(x ^ 2) ) )
# given the cosine value, use acos to convert back to degrees
# acos returns the radian, multiply it by 180 and divide by pi to obtain degrees
return( acos(similarity) * 180 / pi )
}
query <- idf
query[] <- 0
query["kill"] <- idf["kill"]
query["miss"] <- idf["miss"]
query["kidnap"] <- idf["kidnap"]
query["crime"] <- idf["crime"]
query["shoot"] <- idf["shoot"]
query["death"] <- idf["death"]
query["victim"] <- idf["victim"]
query["police"] <- idf["police"]
query["murder"] <- idf["murder"]
query["suspect"] <- idf["suspect"]
query["blood"] <- idf["blood"]
query
qtf.idf <- cbind(tdm,query)
qtf.idf
pr_DB$set_entry(FUN = cosd, names = c("cosd"))
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
View(d1)
library(proxy)
cosd<- function(x, y) {
similarity <- sum(x * y) / ( sqrt( sum(y ^ 2) ) * sqrt( sum(x ^ 2) ) )
# given the cosine value, use acos to convert back to degrees
# acos returns the radian, multiply it by 180 and divide by pi to obtain degrees
return( acos(similarity) * 180 / pi )
}
#pr_DB$set_entry(FUN = cosde, names = c("cosde"))
#d1 <- dist(tf.idf, method = "cosde")
#d1
#summary(pr_DB)
#View(d1)
#cosd <- function(x,y) {
# z <- rbind(x,y)
#z <- as.matrix(z[,colSums(is.na(z)) == 0])
#x <- z[1,]
#y <- z[2,]
#x %*% y / (sqrt(x%*%x) * sqrt(y%*%y))
#}
query <- idf
query[] <- 0
query["kill"] <- idf["kill"]
query["miss"] <- idf["miss"]
query["kidnap"] <- idf["kidnap"]
query["crime"] <- idf["crime"]
query["shoot"] <- idf["shoot"]
query["death"] <- idf["death"]
query["victim"] <- idf["victim"]
query["police"] <- idf["police"]
query["murder"] <- idf["murder"]
query["suspect"] <- idf["suspect"]
query["blood"] <- idf["blood"]
query
qtf.idf <- cbind(tdm,query)
qtf.idf
pr_DB$set_entry(FUN = cosde, names = c("cosd"))
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
library(proxy)
cosd<- function(x, y) {
similarity <- sum(x * y) / ( sqrt( sum(y ^ 2) ) * sqrt( sum(x ^ 2) ) )
# given the cosine value, use acos to convert back to degrees
# acos returns the radian, multiply it by 180 and divide by pi to obtain degrees
return( acos(similarity) * 180 / pi )
}
query <- idf
query[] <- 0
query["kill"] <- idf["kill"]
query["miss"] <- idf["miss"]
query["kidnap"] <- idf["kidnap"]
query["crime"] <- idf["crime"]
query["shoot"] <- idf["shoot"]
query["death"] <- idf["death"]
query["victim"] <- idf["victim"]
query["police"] <- idf["police"]
query["murder"] <- idf["murder"]
query["suspect"] <- idf["suspect"]
query["blood"] <- idf["blood"]
query
qtf.idf <- cbind(tdm,query)
qtf.idf
View(qtf.idf)
qtf.idf[["i"]]
qtf.idf[["j"]]
qtf.idf[["v"]]
qtf.idf[["nrow"]]
qtf.idf[["ncol"]]
qtf.idf[["dimnames"]]
d1 <- dist(qtf.idf, method = "cosd", upper=TRUE)
pr_DB$set_entry(FUN = cosd, names = c("cosd"))
library(proxy)
cosd<- function(x, y) {
similarity <- sum(x * y) / ( sqrt( sum(y ^ 2) ) * sqrt( sum(x ^ 2) ) )
# given the cosine value, use acos to convert back to degrees
# acos returns the radian, multiply it by 180 and divide by pi to obtain degrees
return( acos(similarity) * 180 / pi )
}
setwd("~/Desktop/IR")
library(tm)
library(ggplot2)
#q1#
path = "./Dataset/"
dir = DirSource(paste(path,sep=""), encoding = "UTF-8")
corpus = Corpus(dir)
length(corpus)
#corpus[[1]]$content
#strwrap(corpus)
myStopwords = c(stopwords(),"crime","crimes","security","securities")
tdm = TermDocumentMatrix(corpus,
control = list(weighting = weightTfIdf,
stopwords = myStopwords,
removePunctuation = T,
removeNumbers = T,
stemming = T))
#q3
( tf <- as.matrix(tdm) ) #frequency of each term in entire corpus
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
idf
library(SnowballC)
#inspect(tdm[2005:2015,100:103])
freq=rowSums(as.matrix(tf))
View(freq)
head(freq,10)
tail(freq,10)
barplot(sort(freq, decreasing = T),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
tail(sort(freq),n=10)
high.freq=tail(sort(freq),n=10)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df)
ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Terms") + ylab("Frequency") +
ggtitle("Term frequencies")
# q2
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
#( tf <- as.matrix(tdm) )
#q4
tdm <- TermDocumentMatrix(corpus,list(dictionary=c("kill","miss","kidnap","crime","shoot","death", "victim","police","murder", "suspect","blood")))
( tf <- as.matrix(tdm) )
tfLog  <- ifelse(tf>0,1+log10(tf),0)
View(tfLog)
idf <- tf
idf[idf>0]<-1
idf <- log10(ncol(tf)/rowSums(idf))
View(idf)
tf.idf <- tfLog*idf
View(tf.idf)
freq=rowSums(as.matrix(tf.idf))
View(freq)
head(freq,11)
tail(freq,11)
barplot(sort(decreasing = T, freq),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
tail(sort(freq),n=11)
plot(sort(decreasing = T, freq),col="blue",main="Word TF-IDF frequencies", xlab="TF-IDF-based rank", ylab = "TF-IDF")
tail(sort(freq),n=11)
freq=rowSums(as.matrix(idf))
high.freq=tail(sort(freq),n=11)
hfp.df=as.data.frame(sort(high.freq))
hfp.df$names <- rownames(hfp.df)
ggplot(hfp.df, aes(reorder(names,high.freq), high.freq)) +
geom_bar(stat="identity") + coord_flip() +
xlab("Query Terms") + ylab("IDF") +
ggtitle("IDF Bar Chart")
# Simple Pie Chart
x=freq
pie(x, labels = names(x), edges = 200, radius = 0.8,
)
#q7
library(proxy)
cosd<- function(x, y) {
similarity <- sum(x * y) / ( sqrt( sum(y ^ 2) ) * sqrt( sum(x ^ 2) ) )
# given the cosine value, use acos to convert back to degrees
# acos returns the radian, multiply it by 180 and divide by pi to obtain degrees
return( acos(similarity) * 180 / pi )
}
#}
query <- idf
query[] <- 0
query["kill"] <- idf["kill"]
query["miss"] <- idf["miss"]
query["kidnap"] <- idf["kidnap"]
query["crime"] <- idf["crime"]
query["shoot"] <- idf["shoot"]
query["death"] <- idf["death"]
query["victim"] <- idf["victim"]
query["police"] <- idf["police"]
query["murder"] <- idf["murder"]
query["suspect"] <- idf["suspect"]
query["blood"] <- idf["blood"]
query
qtf.idf <- cbind(tdm,query)
qtf.idf
pr_DB$set_entry(FUN = cosd, names = c("cosd"))
pr_DB$set_entry(FUN = cosde, names = c("cosd"))
cosine_ratings = Cosine(tdm)
cosine_ratings = cosine(tdm)
cosine_ratings = cosine(tf.idf)
cosine_ratings = cosine(tdm)
cosine_ratings = Cosine(tdm)
cosine_ratings = cosd(tdm)
